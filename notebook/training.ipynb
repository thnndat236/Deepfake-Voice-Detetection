{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6310de4e",
   "metadata": {},
   "source": [
    "# Deepfake Voice Detection Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ee324",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8df7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-17 23:04:31.303739: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-17 23:04:31.317471: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-17 23:04:31.850650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-17 23:04:33.705681: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-17 23:04:33.708010: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81698fc4",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230505b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"../data/preprocessed.csv\"\n",
    "DEEPFAKEVOICE_KERAS_MODEL = \"../app/model/deepfakevoice/deepfakevoice_v1.keras\"\n",
    "DEEPFAKEVOICE_SCALER = \"../app/model/deepfakevoice/scaler.joblib\"\n",
    "DEEPFAKEVOICE_TFLITE_MODEL = \"../app/model/deepfakevoice/deepfakevoice.tflite\"\n",
    "DEEPFAKEVOICE_LOGS =  '../app/model/deepfakevoice/deepfakevoice_logs'\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708bd0b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed41b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zcr</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.358431</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>3542.9941</td>\n",
       "      <td>2472.2634</td>\n",
       "      <td>6142.1016</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>-183.50685</td>\n",
       "      <td>34.215317</td>\n",
       "      <td>-25.610506</td>\n",
       "      <td>5.232159</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.175571</td>\n",
       "      <td>-15.062231</td>\n",
       "      <td>-2.411484</td>\n",
       "      <td>-2.136526</td>\n",
       "      <td>4.616874</td>\n",
       "      <td>-3.939895</td>\n",
       "      <td>-5.642972</td>\n",
       "      <td>-8.739243</td>\n",
       "      <td>-9.369484</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.398888</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>2956.4412</td>\n",
       "      <td>2525.6920</td>\n",
       "      <td>5812.9860</td>\n",
       "      <td>0.171032</td>\n",
       "      <td>-350.51126</td>\n",
       "      <td>58.881863</td>\n",
       "      <td>-23.915743</td>\n",
       "      <td>13.723481</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.554494</td>\n",
       "      <td>-8.560787</td>\n",
       "      <td>-2.228989</td>\n",
       "      <td>-14.121045</td>\n",
       "      <td>-0.228751</td>\n",
       "      <td>-2.585350</td>\n",
       "      <td>-3.479854</td>\n",
       "      <td>-10.985688</td>\n",
       "      <td>-4.435715</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.277066</td>\n",
       "      <td>0.028064</td>\n",
       "      <td>2216.6729</td>\n",
       "      <td>2266.4956</td>\n",
       "      <td>4373.1978</td>\n",
       "      <td>0.103405</td>\n",
       "      <td>-328.82240</td>\n",
       "      <td>84.158720</td>\n",
       "      <td>-20.430117</td>\n",
       "      <td>6.658457</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.122506</td>\n",
       "      <td>-6.528575</td>\n",
       "      <td>5.203861</td>\n",
       "      <td>-6.371897</td>\n",
       "      <td>-2.242782</td>\n",
       "      <td>-7.658447</td>\n",
       "      <td>-6.257457</td>\n",
       "      <td>-6.273143</td>\n",
       "      <td>-3.551254</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.359222</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>2968.6410</td>\n",
       "      <td>2467.4130</td>\n",
       "      <td>5483.6260</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>-265.03745</td>\n",
       "      <td>61.225735</td>\n",
       "      <td>-20.567951</td>\n",
       "      <td>-0.498797</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.477275</td>\n",
       "      <td>-14.361066</td>\n",
       "      <td>0.192269</td>\n",
       "      <td>-5.031093</td>\n",
       "      <td>-0.998947</td>\n",
       "      <td>-3.826710</td>\n",
       "      <td>-2.932528</td>\n",
       "      <td>-9.419309</td>\n",
       "      <td>-3.316403</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329339</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>2111.4087</td>\n",
       "      <td>2129.4204</td>\n",
       "      <td>3848.3260</td>\n",
       "      <td>0.105125</td>\n",
       "      <td>-283.91092</td>\n",
       "      <td>91.656950</td>\n",
       "      <td>-41.411015</td>\n",
       "      <td>-11.166985</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.310187</td>\n",
       "      <td>-10.009683</td>\n",
       "      <td>-3.353666</td>\n",
       "      <td>-7.186924</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>-9.301208</td>\n",
       "      <td>-5.654605</td>\n",
       "      <td>-5.261728</td>\n",
       "      <td>2.498810</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_stft       rms  spectral_centroid  spectral_bandwidth    rolloff  \\\n",
       "0     0.358431  0.047544          3542.9941           2472.2634  6142.1016   \n",
       "1     0.398888  0.013980          2956.4412           2525.6920  5812.9860   \n",
       "2     0.277066  0.028064          2216.6729           2266.4956  4373.1978   \n",
       "3     0.359222  0.035303          2968.6410           2467.4130  5483.6260   \n",
       "4     0.329339  0.024873          2111.4087           2129.4204  3848.3260   \n",
       "\n",
       "        zcr      mfcc1      mfcc2      mfcc3      mfcc4  ...     mfcc12  \\\n",
       "0  0.229714 -183.50685  34.215317 -25.610506   5.232159  ... -14.175571   \n",
       "1  0.171032 -350.51126  58.881863 -23.915743  13.723481  ...  -9.554494   \n",
       "2  0.103405 -328.82240  84.158720 -20.430117   6.658457  ...  -9.122506   \n",
       "3  0.178067 -265.03745  61.225735 -20.567951  -0.498797  ...  -6.477275   \n",
       "4  0.105125 -283.91092  91.656950 -41.411015 -11.166985  ...  -2.310187   \n",
       "\n",
       "      mfcc13    mfcc14     mfcc15    mfcc16    mfcc17    mfcc18     mfcc19  \\\n",
       "0 -15.062231 -2.411484  -2.136526  4.616874 -3.939895 -5.642972  -8.739243   \n",
       "1  -8.560787 -2.228989 -14.121045 -0.228751 -2.585350 -3.479854 -10.985688   \n",
       "2  -6.528575  5.203861  -6.371897 -2.242782 -7.658447 -6.257457  -6.273143   \n",
       "3 -14.361066  0.192269  -5.031093 -0.998947 -3.826710 -2.932528  -9.419309   \n",
       "4 -10.009683 -3.353666  -7.186924 -0.003199 -9.301208 -5.654605  -5.261728   \n",
       "\n",
       "     mfcc20  label  \n",
       "0 -9.369484   REAL  \n",
       "1 -4.435715   REAL  \n",
       "2 -3.551254   REAL  \n",
       "3 -3.316403   REAL  \n",
       "4  2.498810   REAL  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db81527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes: ['FAKE' 'REAL']\n",
      "Shapes: (33555, 26) (8389, 26) (10486, 26)\n"
     ]
    }
   ],
   "source": [
    "label_col = \"label\"\n",
    "\n",
    "# Encode label (REAL -> 1, FAKE -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "df[label_col] = label_encoder.fit_transform(df[label_col])\n",
    "\n",
    "print(\"Label classes:\", label_encoder.classes_)\n",
    "\n",
    "# Split features/labels\n",
    "X_full = df.drop(columns=[label_col]).values.astype(np.float32)\n",
    "y_full = df[label_col].values.astype(np.int32)\n",
    "\n",
    "# Train/Val/Test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91255e6",
   "metadata": {},
   "source": [
    "## Preprocessing: Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97e3c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../app/model/deepfakevoice/scaler.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for later (inference)\n",
    "import joblib\n",
    "joblib.dump(scaler, DEEPFAKEVOICE_SCALER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c37da",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea64198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760717103.698770   16960 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1760717103.706903   16960 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m6,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,449</span> (220.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,449\u001b[0m (220.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,449</span> (220.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,449\u001b[0m (220.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "\n",
    "dropout_rate=0.35\n",
    "l2_reg=1e-4\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(n_features,), name=\"mfcc_input\"),\n",
    "    tf.keras.layers.Dense(256, activation=tf.keras.layers.PReLU(),\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(128, activation=tf.keras.layers.PReLU(),\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(128, activation=tf.keras.layers.PReLU(),\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2158f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[tf.keras.metrics.AUC(name=\"auc\"), \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e173b61",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0785248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../app/model/deepfakevoice/deepfakevoice_logs/run_003')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 3 # increment this at every run\n",
    "run_logdir = Path(DEEPFAKEVOICE_LOGS) / \"run_{:03d}\".format(run_index)\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0e4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(DEEPFAKEVOICE_KERAS_MODEL, monitor=\"val_auc\", save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=10, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, patience=5, mode=\"max\", verbose=1)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff18c7",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c2f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "525/525 - 3s - 6ms/step - accuracy: 0.8200 - auc: 0.9021 - loss: 0.4990 - val_accuracy: 0.9412 - val_auc: 0.9855 - val_loss: 0.2622 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9153 - auc: 0.9709 - loss: 0.3126 - val_accuracy: 0.9472 - val_auc: 0.9913 - val_loss: 0.2274 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9312 - auc: 0.9801 - loss: 0.2671 - val_accuracy: 0.9546 - val_auc: 0.9922 - val_loss: 0.2039 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9420 - auc: 0.9846 - loss: 0.2393 - val_accuracy: 0.9622 - val_auc: 0.9947 - val_loss: 0.1816 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n",
      "525/525 - 3s - 5ms/step - accuracy: 0.9456 - auc: 0.9872 - loss: 0.2205 - val_accuracy: 0.9635 - val_auc: 0.9947 - val_loss: 0.1741 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9514 - auc: 0.9890 - loss: 0.2041 - val_accuracy: 0.9665 - val_auc: 0.9957 - val_loss: 0.1608 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9537 - auc: 0.9902 - loss: 0.1928 - val_accuracy: 0.9684 - val_auc: 0.9962 - val_loss: 0.1528 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9553 - auc: 0.9911 - loss: 0.1834 - val_accuracy: 0.9713 - val_auc: 0.9968 - val_loss: 0.1472 - learning_rate: 1.0000e-03\n",
      "Epoch 9/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9588 - auc: 0.9915 - loss: 0.1747 - val_accuracy: 0.9720 - val_auc: 0.9972 - val_loss: 0.1338 - learning_rate: 1.0000e-03\n",
      "Epoch 10/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9611 - auc: 0.9932 - loss: 0.1626 - val_accuracy: 0.9743 - val_auc: 0.9970 - val_loss: 0.1275 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "525/525 - 2s - 5ms/step - accuracy: 0.9629 - auc: 0.9932 - loss: 0.1570 - val_accuracy: 0.9737 - val_auc: 0.9970 - val_loss: 0.1273 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "525/525 - 2s - 5ms/step - accuracy: 0.9642 - auc: 0.9940 - loss: 0.1510 - val_accuracy: 0.9754 - val_auc: 0.9974 - val_loss: 0.1182 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9680 - auc: 0.9943 - loss: 0.1453 - val_accuracy: 0.9775 - val_auc: 0.9982 - val_loss: 0.1153 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9662 - auc: 0.9947 - loss: 0.1413 - val_accuracy: 0.9763 - val_auc: 0.9977 - val_loss: 0.1148 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9674 - auc: 0.9947 - loss: 0.1382 - val_accuracy: 0.9778 - val_auc: 0.9982 - val_loss: 0.1081 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9698 - auc: 0.9953 - loss: 0.1319 - val_accuracy: 0.9781 - val_auc: 0.9981 - val_loss: 0.1072 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9695 - auc: 0.9957 - loss: 0.1272 - val_accuracy: 0.9812 - val_auc: 0.9981 - val_loss: 0.1029 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9710 - auc: 0.9955 - loss: 0.1258 - val_accuracy: 0.9791 - val_auc: 0.9982 - val_loss: 0.1013 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9743 - auc: 0.9964 - loss: 0.1169 - val_accuracy: 0.9843 - val_auc: 0.9987 - val_loss: 0.0920 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9743 - auc: 0.9967 - loss: 0.1142 - val_accuracy: 0.9807 - val_auc: 0.9987 - val_loss: 0.0952 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9749 - auc: 0.9971 - loss: 0.1094 - val_accuracy: 0.9845 - val_auc: 0.9989 - val_loss: 0.0860 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9763 - auc: 0.9972 - loss: 0.1072 - val_accuracy: 0.9812 - val_auc: 0.9989 - val_loss: 0.0908 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "525/525 - 3s - 5ms/step - accuracy: 0.9765 - auc: 0.9971 - loss: 0.1060 - val_accuracy: 0.9850 - val_auc: 0.9990 - val_loss: 0.0839 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9776 - auc: 0.9974 - loss: 0.1024 - val_accuracy: 0.9850 - val_auc: 0.9988 - val_loss: 0.0847 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9775 - auc: 0.9974 - loss: 0.1017 - val_accuracy: 0.9843 - val_auc: 0.9988 - val_loss: 0.0840 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9773 - auc: 0.9974 - loss: 0.1007 - val_accuracy: 0.9851 - val_auc: 0.9990 - val_loss: 0.0818 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9801 - auc: 0.9979 - loss: 0.0939 - val_accuracy: 0.9833 - val_auc: 0.9992 - val_loss: 0.0813 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9802 - auc: 0.9980 - loss: 0.0921 - val_accuracy: 0.9850 - val_auc: 0.9990 - val_loss: 0.0796 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9804 - auc: 0.9979 - loss: 0.0921 - val_accuracy: 0.9858 - val_auc: 0.9992 - val_loss: 0.0766 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9805 - auc: 0.9979 - loss: 0.0925 - val_accuracy: 0.9866 - val_auc: 0.9992 - val_loss: 0.0746 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9804 - auc: 0.9980 - loss: 0.0913 - val_accuracy: 0.9874 - val_auc: 0.9992 - val_loss: 0.0731 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9809 - auc: 0.9982 - loss: 0.0877 - val_accuracy: 0.9876 - val_auc: 0.9992 - val_loss: 0.0721 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9810 - auc: 0.9980 - loss: 0.0890 - val_accuracy: 0.9863 - val_auc: 0.9992 - val_loss: 0.0739 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9822 - auc: 0.9983 - loss: 0.0856 - val_accuracy: 0.9876 - val_auc: 0.9992 - val_loss: 0.0720 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9823 - auc: 0.9983 - loss: 0.0853 - val_accuracy: 0.9884 - val_auc: 0.9993 - val_loss: 0.0701 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9840 - auc: 0.9984 - loss: 0.0823 - val_accuracy: 0.9878 - val_auc: 0.9991 - val_loss: 0.0716 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9829 - auc: 0.9985 - loss: 0.0823 - val_accuracy: 0.9866 - val_auc: 0.9993 - val_loss: 0.0718 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9827 - auc: 0.9982 - loss: 0.0847 - val_accuracy: 0.9880 - val_auc: 0.9993 - val_loss: 0.0699 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9836 - auc: 0.9987 - loss: 0.0805 - val_accuracy: 0.9886 - val_auc: 0.9994 - val_loss: 0.0678 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9846 - auc: 0.9986 - loss: 0.0789 - val_accuracy: 0.9887 - val_auc: 0.9993 - val_loss: 0.0686 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9832 - auc: 0.9986 - loss: 0.0809 - val_accuracy: 0.9883 - val_auc: 0.9994 - val_loss: 0.0680 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "525/525 - 3s - 5ms/step - accuracy: 0.9839 - auc: 0.9986 - loss: 0.0801 - val_accuracy: 0.9893 - val_auc: 0.9994 - val_loss: 0.0671 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9845 - auc: 0.9987 - loss: 0.0793 - val_accuracy: 0.9893 - val_auc: 0.9994 - val_loss: 0.0663 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9842 - auc: 0.9986 - loss: 0.0792 - val_accuracy: 0.9887 - val_auc: 0.9994 - val_loss: 0.0674 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9843 - auc: 0.9985 - loss: 0.0806 - val_accuracy: 0.9888 - val_auc: 0.9993 - val_loss: 0.0672 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9841 - auc: 0.9986 - loss: 0.0796 - val_accuracy: 0.9894 - val_auc: 0.9994 - val_loss: 0.0663 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9839 - auc: 0.9987 - loss: 0.0781 - val_accuracy: 0.9889 - val_auc: 0.9994 - val_loss: 0.0666 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9841 - auc: 0.9985 - loss: 0.0784 - val_accuracy: 0.9886 - val_auc: 0.9994 - val_loss: 0.0665 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9841 - auc: 0.9984 - loss: 0.0797 - val_accuracy: 0.9893 - val_auc: 0.9994 - val_loss: 0.0654 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9842 - auc: 0.9987 - loss: 0.0783 - val_accuracy: 0.9889 - val_auc: 0.9994 - val_loss: 0.0665 - learning_rate: 3.1250e-05\n",
      "Epoch 51/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9839 - auc: 0.9985 - loss: 0.0797 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0656 - learning_rate: 3.1250e-05\n",
      "Epoch 52/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9847 - auc: 0.9987 - loss: 0.0774 - val_accuracy: 0.9883 - val_auc: 0.9994 - val_loss: 0.0669 - learning_rate: 3.1250e-05\n",
      "Epoch 53/100\n",
      "525/525 - 3s - 6ms/step - accuracy: 0.9855 - auc: 0.9988 - loss: 0.0754 - val_accuracy: 0.9888 - val_auc: 0.9994 - val_loss: 0.0664 - learning_rate: 3.1250e-05\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9849 - auc: 0.9988 - loss: 0.0765 - val_accuracy: 0.9895 - val_auc: 0.9994 - val_loss: 0.0655 - learning_rate: 3.1250e-05\n",
      "Epoch 55/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9853 - auc: 0.9987 - loss: 0.0764 - val_accuracy: 0.9893 - val_auc: 0.9994 - val_loss: 0.0650 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9857 - auc: 0.9988 - loss: 0.0751 - val_accuracy: 0.9889 - val_auc: 0.9994 - val_loss: 0.0651 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "525/525 - 3s - 5ms/step - accuracy: 0.9843 - auc: 0.9988 - loss: 0.0776 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0652 - learning_rate: 1.5625e-05\n",
      "Epoch 58/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9844 - auc: 0.9985 - loss: 0.0777 - val_accuracy: 0.9887 - val_auc: 0.9994 - val_loss: 0.0658 - learning_rate: 1.5625e-05\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9840 - auc: 0.9986 - loss: 0.0776 - val_accuracy: 0.9889 - val_auc: 0.9994 - val_loss: 0.0653 - learning_rate: 1.5625e-05\n",
      "Epoch 60/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9854 - auc: 0.9987 - loss: 0.0766 - val_accuracy: 0.9888 - val_auc: 0.9994 - val_loss: 0.0657 - learning_rate: 7.8125e-06\n",
      "Epoch 61/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9845 - auc: 0.9988 - loss: 0.0764 - val_accuracy: 0.9887 - val_auc: 0.9994 - val_loss: 0.0657 - learning_rate: 7.8125e-06\n",
      "Epoch 62/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9847 - auc: 0.9988 - loss: 0.0771 - val_accuracy: 0.9887 - val_auc: 0.9994 - val_loss: 0.0654 - learning_rate: 7.8125e-06\n",
      "Epoch 63/100\n",
      "525/525 - 3s - 5ms/step - accuracy: 0.9844 - auc: 0.9988 - loss: 0.0771 - val_accuracy: 0.9888 - val_auc: 0.9994 - val_loss: 0.0654 - learning_rate: 7.8125e-06\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "525/525 - 3s - 6ms/step - accuracy: 0.9855 - auc: 0.9987 - loss: 0.0760 - val_accuracy: 0.9892 - val_auc: 0.9994 - val_loss: 0.0648 - learning_rate: 7.8125e-06\n",
      "Epoch 65/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9844 - auc: 0.9987 - loss: 0.0772 - val_accuracy: 0.9892 - val_auc: 0.9994 - val_loss: 0.0649 - learning_rate: 3.9063e-06\n",
      "Epoch 66/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9851 - auc: 0.9986 - loss: 0.0766 - val_accuracy: 0.9892 - val_auc: 0.9994 - val_loss: 0.0647 - learning_rate: 3.9063e-06\n",
      "Epoch 67/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9843 - auc: 0.9987 - loss: 0.0775 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0649 - learning_rate: 3.9063e-06\n",
      "Epoch 68/100\n",
      "525/525 - 3s - 7ms/step - accuracy: 0.9844 - auc: 0.9988 - loss: 0.0761 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0649 - learning_rate: 3.9063e-06\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9848 - auc: 0.9988 - loss: 0.0758 - val_accuracy: 0.9892 - val_auc: 0.9994 - val_loss: 0.0648 - learning_rate: 3.9063e-06\n",
      "Epoch 70/100\n",
      "525/525 - 2s - 4ms/step - accuracy: 0.9845 - auc: 0.9989 - loss: 0.0753 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0648 - learning_rate: 1.9531e-06\n",
      "Epoch 71/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9848 - auc: 0.9987 - loss: 0.0757 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0647 - learning_rate: 1.9531e-06\n",
      "Epoch 72/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9847 - auc: 0.9988 - loss: 0.0765 - val_accuracy: 0.9892 - val_auc: 0.9994 - val_loss: 0.0648 - learning_rate: 1.9531e-06\n",
      "Epoch 73/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9854 - auc: 0.9988 - loss: 0.0751 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0649 - learning_rate: 1.9531e-06\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9848 - auc: 0.9987 - loss: 0.0767 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0648 - learning_rate: 1.9531e-06\n",
      "Epoch 75/100\n",
      "525/525 - 1s - 3ms/step - accuracy: 0.9848 - auc: 0.9985 - loss: 0.0773 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0648 - learning_rate: 9.7656e-07\n",
      "Epoch 76/100\n",
      "525/525 - 2s - 3ms/step - accuracy: 0.9840 - auc: 0.9988 - loss: 0.0762 - val_accuracy: 0.9890 - val_auc: 0.9994 - val_loss: 0.0647 - learning_rate: 9.7656e-07\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler, tensorboard_cb],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc09ea",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8313e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test set:\n",
      "328/328 - 1s - 2ms/step - accuracy: 0.9879 - auc: 0.9993 - loss: 0.0684\n",
      "[0.06835038214921951, 0.9992964267730713, 0.9878886342048645]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test set:\")\n",
    "model = tf.keras.models.load_model(DEEPFAKEVOICE_KERAS_MODEL) # rollback to best model\n",
    "res = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99280a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.98      0.99      5237\n",
      "        REAL       0.98      1.00      0.99      5249\n",
      "\n",
      "    accuracy                           0.99     10486\n",
      "   macro avg       0.99      0.99      0.99     10486\n",
      "weighted avg       0.99      0.99      0.99     10486\n",
      "\n",
      "Confusion matrix:\n",
      " [[5118  119]\n",
      " [   8 5241]]\n"
     ]
    }
   ],
   "source": [
    "# predict & classification report\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"FAKE\",\"REAL\"]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6bc1332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../app/model/deepfakevoice/deepfakevoice_logs\n",
      "          run_001\n",
      "            train\n",
      "              events.out.tfevents.1760288310.LAPTOPTHNNDAT.24415.0.v2\n",
      "              events.out.tfevents.1760288638.LAPTOPTHNNDAT.24415.2.v2\n",
      "            validation\n",
      "              events.out.tfevents.1760288313.LAPTOPTHNNDAT.24415.1.v2\n",
      "              events.out.tfevents.1760288640.LAPTOPTHNNDAT.24415.3.v2\n",
      "          run_002\n",
      "            train\n",
      "              events.out.tfevents.1760368612.LAPTOPTHNNDAT.9851.0.v2\n",
      "            validation\n",
      "              events.out.tfevents.1760368615.LAPTOPTHNNDAT.9851.1.v2\n",
      "          run_003\n",
      "            train\n",
      "              events.out.tfevents.1760717118.LAPTOPTHNNDAT.16960.0.v2\n",
      "            validation\n",
      "              events.out.tfevents.1760717121.LAPTOPTHNNDAT.16960.1.v2\n"
     ]
    }
   ],
   "source": [
    "print(DEEPFAKEVOICE_LOGS)\n",
    "for path in sorted(Path(DEEPFAKEVOICE_LOGS).glob(\"**/*\")):\n",
    "    print(\"  \" * (len(path.parts) - 1) + path.parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a760636a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd1024210878a53b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd1024210878a53b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=../app/model/deepfakevoice/deepfakevoice_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7c0f7",
   "metadata": {},
   "source": [
    "## Convert to TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a438537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxlvzyo13/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxlvzyo13/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpxlvzyo13'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 26), dtype=tf.float32, name='mfcc_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  136892019898880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020325216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020147824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020791904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020786272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020787504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020792256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136891820430208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136892020799824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136891820434432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136891820429152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1760717293.889692   16960 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1760717293.889740   16960 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-17 23:08:13.890130: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpxlvzyo13\n",
      "2025-10-17 23:08:13.890886: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-17 23:08:13.890901: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpxlvzyo13\n",
      "I0000 00:00:1760717293.897323   16960 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-10-17 23:08:13.898832: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-17 23:08:13.943799: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpxlvzyo13\n",
      "2025-10-17 23:08:13.955650: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 65522 microseconds.\n",
      "2025-10-17 23:08:13.992934: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(DEEPFAKEVOICE_TFLITE_MODEL, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2626d",
   "metadata": {},
   "source": [
    "# Inference TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f660aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c40692",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_REAL = \"../data/DEMONSTRATION/linus-original-DEMO.mp3\"\n",
    "AUDIO_FAKE = \"../data/DEMONSTRATION/linus-to-musk-DEMO.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aceda16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_per_segment(audio_segment, sr=22050):\n",
    "    segment_samples = sr\n",
    "    try:\n",
    "        # Pad or truncate to ensure segment is correct length\n",
    "        if len(audio_segment) < segment_samples :\n",
    "            audio_segment = np.pad(audio_segment, (0, segment_samples - len(audio_segment)))\n",
    "        elif len(audio_segment) > segment_samples:\n",
    "            audio_segment = audio_segment[:segment_samples]\n",
    "        \n",
    "        # Extract 6 statistical features\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio_segment, sr=sr))\n",
    "        rms = np.mean(librosa.feature.rms(y=audio_segment))\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio_segment, sr=sr))\n",
    "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio_segment, sr=sr))\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio_segment, sr=sr))\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(y=audio_segment))\n",
    "\n",
    "        # Extract 20 MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=audio_segment, sr=sr, n_mfcc=20)\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "        # Combine all features\n",
    "        features = np.array([chroma_stft, rms, spectral_centroid, spectral_bandwidth, spectral_rolloff, zcr, *mfccs_mean], dtype=np.float32)\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Feature extraction failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1374475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_path, sr=22050):\n",
    "    \"\"\"\n",
    "    Extract feature entire audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "\n",
    "        # Calculate number of 1-second segments\n",
    "        segment_len = sr\n",
    "        num_segments = int(np.ceil(len(y) / segment_len))\n",
    "\n",
    "        features_list = []\n",
    "        \n",
    "        # Extract feature of 1-second segment audio\n",
    "        for i in range(num_segments):\n",
    "            start = i * segment_len\n",
    "            end = min((i + 1) * segment_len, len(y))\n",
    "            y_segment = y[start:end]\n",
    "\n",
    "            features = extract_features_per_segment(y_segment, sr)\n",
    "            features_list.append(features)\n",
    "\n",
    "        return np.array(features_list)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc3256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(DEEPFAKEVOICE_SCALER)\n",
    "\n",
    "real_features = extract_feature(AUDIO_REAL)\n",
    "real_scaled_features = scaler.transform(real_features)\n",
    "fake_features = extract_feature(AUDIO_FAKE)\n",
    "fake_scaled_features = scaler.transform(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e702ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760720450.600443   37115 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "from ai_edge_litert.interpreter import Interpreter\n",
    "\n",
    "# Load and allocate the TFLite interpreter\n",
    "interpreter = Interpreter(\n",
    "    model_path=DEEPFAKEVOICE_TFLITE_MODEL,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30905136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    batch_size = features.shape[0]\n",
    "    interpreter.resize_tensor_input(\n",
    "        input_details[0]['index'],\n",
    "        [batch_size, features.shape[1]]\n",
    "    )\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "    interpreter.set_tensor(\n",
    "        input_details[0]['index'],\n",
    "        features\n",
    "    )\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output tensor\n",
    "    result = interpreter.get_tensor(\n",
    "        output_details[0]['index']\n",
    "    )\n",
    "\n",
    "    # Squeeze output to remove extra dimensions\n",
    "    probs = np.squeeze(result)\n",
    "\n",
    "    # Threshold at 0.5 to get binary prediction (1: REAL if probs > 0.5)\n",
    "    if probs.ndim == 0:\n",
    "        # Single sample case: return scalar index\n",
    "        result_index = 1 if probs > 0.5 else 0\n",
    "    else:\n",
    "        # Batch case: return array of indices\n",
    "        result_index = (probs > 0.5).astype(int)\n",
    "\n",
    "    if np.average(result_index) < 0.5:\n",
    "        print(\"\\tPrediction: Fake\")\n",
    "    else:\n",
    "        print(\"\\tPrediction: Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978d094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real audio predict:\n",
      "\tPrediction: Real\n",
      "Fake audio predict:\n",
      "\tPrediction: Fake\n"
     ]
    }
   ],
   "source": [
    "print(\"Real audio predict:\")\n",
    "predict(real_scaled_features)\n",
    "print(\"Fake audio predict:\")\n",
    "predict(fake_scaled_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-voice-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
