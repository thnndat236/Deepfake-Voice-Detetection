{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29ed738",
   "metadata": {},
   "source": [
    "# Preprocess Raw Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9204aad",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dafe265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4f96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_ROOT = \"../data/AUDIO\"\n",
    "OUTPUT_CSV = \"../data/preprocessed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95861e2",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db47e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_per_segment(audio_segment, sr=22050):\n",
    "    segment_samples = sr\n",
    "    try:\n",
    "        # Pad or truncate to ensure segment is correct length\n",
    "        if len(audio_segment) < segment_samples :\n",
    "            audio_segment = np.pad(audio_segment, (0, segment_samples - len(audio_segment)))\n",
    "        elif len(audio_segment) > segment_samples:\n",
    "            audio_segment = audio_segment[:segment_samples]\n",
    "        \n",
    "        # Extract 6 statistical features\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio_segment, sr=sr))\n",
    "        rms = np.mean(librosa.feature.rms(y=audio_segment))\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio_segment, sr=sr))\n",
    "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio_segment, sr=sr))\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio_segment, sr=sr))\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(y=audio_segment))\n",
    "\n",
    "        # Extract 20 MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=audio_segment, sr=sr, n_mfcc=20)\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "        # Combine all features\n",
    "        features = np.array([chroma_stft, rms, spectral_centroid, spectral_bandwidth, spectral_rolloff, zcr, *mfccs_mean], dtype=np.float32)\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Feature extraction failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953eceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_path, sr=22050):\n",
    "    \"\"\"\n",
    "    Extract feature entire audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "\n",
    "        # Calculate number of 1-second segments\n",
    "        segment_len = sr\n",
    "        num_segments = int(np.ceil(len(y) / segment_len))\n",
    "\n",
    "        features_list = []\n",
    "        \n",
    "        # Extract feature of 1-second segment audio\n",
    "        for i in range(num_segments):\n",
    "            start = i * segment_len\n",
    "            end = min((i + 1) * segment_len, len(y))\n",
    "            y_segment = y[start:end]\n",
    "\n",
    "            features = extract_features_per_segment(y_segment, sr)\n",
    "            features_list.append(features)\n",
    "\n",
    "        return np.array(features_list)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880588e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing REAL: 100%|██████████| 8/8 [01:18<00:00,  9.78s/it]\n",
      "Processing FAKE: 100%|██████████| 56/56 [09:33<00:00, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 29965\n",
      "Feature shape: (29965, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(AUDIO_ROOT)\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(AUDIO_ROOT, folder))\n",
    "    for file in tqdm(files, desc=f\"Processing {folder}\"):\n",
    "        file_path = os.path.join(AUDIO_ROOT, folder, file)\n",
    "        features = extract_feature(file_path)\n",
    "\n",
    "\n",
    "        if features is not None:\n",
    "            # Append all segments from this file\n",
    "            data.extend(features)\n",
    "            labels.extend([folder] * len(features))\n",
    "\n",
    "# Convert to numpy array\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(f\"Feature shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c49be",
   "metadata": {},
   "source": [
    "## Oversampling with RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d89a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling:\n",
      "FAKE: 26215\n",
      "REAL: 3750\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution before oversampling:\")\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc6bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying oversampling...\n",
      "Total samples after oversampling: 52430\n",
      "Class distribution after oversampling:\n",
      "FAKE: 26215\n",
      "REAL: 26215\n"
     ]
    }
   ],
   "source": [
    "# Encode label (REAL -> 1, FAKE -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Apply oversampling\n",
    "print(\"Applying oversampling...\")\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "data_resampled, labels_encoded_resampled = ros.fit_resample(data, labels_encoded)\n",
    "\n",
    "# Decode labels back\n",
    "labels_resampled = label_encoder.inverse_transform(labels_encoded_resampled)\n",
    "\n",
    "print(f\"Total samples after oversampling: {len(data_resampled)}\")\n",
    "print(f\"Class distribution after oversampling:\")\n",
    "unique, counts = np.unique(labels_resampled, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc3535",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810679cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 52430\n",
      "Columns: ['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zcr', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n",
      "Dataset saved to ../data/preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "feature_columns = [\"chroma_stft\", \"rms\", \"spectral_centroid\", \"spectral_bandwidth\", \n",
    "                    \"rolloff\", \"zcr\"] + [f\"mfcc{i+1}\" for i in range(20)]\n",
    "\n",
    "df = pd.DataFrame(data_resampled, columns=feature_columns)\n",
    "df[\"label\"] = labels_resampled\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Dataset saved to {OUTPUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-voice-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
